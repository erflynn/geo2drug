

# Compare to other models:
0. our model then cluster (heuristic)
1. logistic w lasso (glmnet)
2. SVM
3. LDA
4. KNN
5. RandomForest
6. PR regression

Load packages and data
```{r}
source('code/utils/assessment_utils.R')
require('tidymodels')


ss <- read_process_ds("human", "06_single_sex", "single_sex")
train <- read_process_ds("human", "03_silver_std", "train_common")
train_full <- read_process_ds("human", "03_silver_std", "train_full")
test <- read_process_ds("human", "03_silver_std", "testing")
test_full <- read_process_ds("human", "03_silver_std", "testing_full")

#training <- data.frame(t(train_expr))
#training$sex <- as.factor(train_lab[rownames(training)])
```

Load the f and m genes and xy genes as a first pass
```{r}
fgenes <- read_csv("data/03_silver_std/human/04_meta_res/fgenes.csv")
mgenes <- read_csv("data/03_silver_std/human/04_meta_res/mgenes.csv")
sex_lab_genes <- c(fgenes$entrezgene_id, mgenes$entrezgene_id)

miceadds::load.Rdata("../gpl_ref/human_xy_genes.RData", "xy_genes")
xy_genes <- xy_genes %>% filter(!is.na(gene)) %>% unique()
x_genes <- xy_genes %>% filter(chr=="X")
y_genes <- xy_genes %>% filter(chr=="Y")
xy_gene_ids <- sapply(xy_genes$gene, as.character)
sex_chr <- intersect(xy_gene_ids, rownames(train[[1]]$expr))
```


Generate a smaller dataset with just the sex chromosome genes and 500 samples for viewing
```{r}
smallDS <- function(dat, genes, num_samples=500){
  dat_exp <- dat$expr[genes,]
  keep.cols <- sample(ncol(dat_exp), num_samples)
  
  dat_exp2 <- dat_exp[,keep.cols]
  dat_lab2 <- (dat$lab)[keep.cols]
  dat_df <- data.frame(t(dat_exp2))
  dat_df$sex <- as.factor(dat_lab2)
  return(dat_df)
}

set.seed(5)
mm_df <- smallDS(train[[1]], sex_chr)
ss_df <- smallDS(ss[[1]], sex_chr)

```

TODO:
- do we see differences in values of mm_df and ss_df
- compare on a gene-by-gene basis
- how do these look in PC-space
```{r}
```


Preprocessing with recipe
a) assess missingness - examine number missing
```{r}
library(naniar)
vis_miss(mm_df)
vis_miss(ss_df)

missHist <- function(my.df){
  my.df <- my.df %>% select(-sex)
  na_rows <- apply(my.df, 1, function(x) sum(is.na(x)))
  na_cols <- apply(my.df, 2, function(x) sum(is.na(x)))
  
  par(mfrow=c(1,2))
  hist(na_rows, main="Number of gene values missing per sample")
  abline(v=(0.3*ncol(my.df)), col="red")
  hist(na_cols, main="Number of values missing per gene")
  abline(v=(0.3*nrow(my.df)), col="red")
}

missHist(mm_df)
missHist(ss_df)

# // TODO should we further filter for no more than 1/3 missingness?
# -- answer: yes, remove GENES then samples
filterMiss <- function(my.df){
  my.df2 <- my.df[,apply(my.df, 2, function(x) sum(is.na(x)) <= 0.3*ncol(my.df))]
  my.df3 <- my.df2[apply(my.df2, 1, function(x) sum(is.na(x)) <= 0.3*nrow(my.df2)),]
  return(my.df3)
}
mm_df2 <- filterMiss(mm_df)
ss_df2 <- filterMiss(ss_df)

```

Uses recipes to pre-process
```{r}
rec_obj <- recipe(sex ~ ., data=head(mm_df2, 10)) 
# we get stack overflow if we try to do everything :P... and it's v slow

impute_trans <- rec_obj %>%
  step_knnimpute(all_predictors(), -all_outcomes())  %>% # impute
  step_corr(all_predictors()) %>% # remove highly correlated predictors
  step_center(all_predictors()) %>%
  step_scale(all_predictors())

# if we remove all NAs, we lose a ton!
#remove_trans <- rec_obj %>%
#  step_naomit(all_predictors())

#step_corr() # remove vars that have large absolute corr w other vals

pca_trans <- impute_trans %>%
  step_pca(all_predictors(), num_comp=4) # 
  
trained_rec <- prep(impute_trans, training=mm_df2)
mm_t <- juice(trained_rec)
ss_t <- bake(trained_rec, new_data=ss_df2)

pca_rec <- prep(pca_trans, training=mm_df2)
mm_p <- juice(pca_rec)
ss_p <- bake(pca_rec, new_data=ss_df2)

```

# train a model!!
```{r}
# random forest
mm_rf <-  rand_forest(trees = 100, mode = "classification") %>%
  set_engine("randomForest") %>%
  fit(sex ~ ., data = mm_t)

predict(mm_rf, ss_t, type="prob") %>%
  bind_cols(ss_t) %>%
  roc_curve(sex, .pred_0) %>%
  autoplot()

predict(mm_rf, ss_t, type = "prob") %>%
  bind_cols(predict(mm_rf, ss_t)) %>%
  bind_cols(select(ss_t, sex)) %>%
  metrics(sex, .pred_0, estimate = .pred_class)

predict(mm_rf, ss_t, type = "prob") %>%
  bind_cols(predict(mm_rf, ss_t)) %>%
  bind_cols(select(ss_t, sex)) %>%
conf_mat(sex, .pred_class) 
# glmnet

logistic_glmnet <-
  logistic_reg(mode = "classification", penalty=0.1, mixture=1) %>%
  # mixture=0 is ridge, mixture=1 is lasso ?
  # penalty is the lambda value ?
  set_engine("glmnet", family="binomial") %>%
  fit(sex ~ ., data = mm_t)

predict(logistic_glmnet, ss_t, type = "prob") %>%
  bind_cols(predict(logistic_glmnet, ss_t)) %>%
  bind_cols(select(ss_t, sex)) %>%
  metrics(sex, .pred_0, estimate = .pred_class)


logistic_p <-
  logistic_reg(mode = "classification") %>%
  set_engine("glm") %>%
  fit(sex ~ ., data = mm_p)

predict(logistic_p, ss_p, type = "prob") %>%
  bind_cols(predict(logistic_p, ss_p)) %>%
  bind_cols(select(ss_p, sex)) %>%
  metrics(sex, .pred_0, estimate = .pred_class)


### // TODO - learn how to tune things!
svm_mod <-
  svm_rbf(cost = tune(), rbf_sigma = tune()) %>%
  set_mode("classification") %>%
  set_engine("kernlab")

```

# plot the ROCs

```{r}
```